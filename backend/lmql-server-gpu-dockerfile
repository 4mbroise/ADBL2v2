FROM nvidia/cuda:12.5.0-devel-ubuntu22.04

RUN apt-get update --yes --quiet && DEBIAN_FRONTEND=noninteractive apt-get install --yes --quiet --no-install-recommends \
    software-properties-common \
    build-essential apt-utils \
    python3.10 \
    pip \
    wget \
    wget curl vim git ca-certificates kmod \
 && rm -rf /var/lib/apt/lists/*

RUN git clone https://github.com/ggerganov/llama.cpp
WORKDIR "/llama.cpp"
RUN make LLAMA_CUDA=1
RUN pip install sentencepiece --no-cache-dir
RUN CMAKE_ARGS="-DLLAMA_CUDA=on" pip install llama-cpp-python --no-cache-dir 

RUN pip install lmql[hf]
RUN pip install peft


WORKDIR /
COPY backend/entrypoint.sh /entrypoint.sh
ENTRYPOINT ["/entrypoint.sh"]

EXPOSE 4000
CMD ["lmql", "serve-model", "google/gemma-2b", "--port", "4000", "--cuda", "--host", "0.0.0.0"]
